# # Телеком: отток клиентов

## Задача

В рамках борьбы за уменьшение оттока клиентов оператор связи планирует предлагать скидки и специальные предложения клиентам, которые хотят уйти. Для этого ему необходимо научиться прогнозировать отток клиентов, а именно: __классифицировать клиентов на тех, кто уйдет, и тех кто останется__. Оператор собрал информацию об тарифах и договорах клиентов, об услугах, которые подключили клиенты и некоторые их персональные данные.

__Основная задача:__ подготовить модель, которая могла бы решать задачу классификации клиентов на потенциально уходящих и на отсающихся. Ключевая метрика по настоянию заказчика - roc-auc, но также просьба включить более наглядный для коллег из бизнеса показатель accuracy.  

__Дополнительная задача:__ коллеги из маркетинга просят проанализировать группы оставшихся и ушедших клиентов. Необходимо сравнить распределения величин ежемесячных платежей (MonthlyCharges)посчитать статистики (средние, минимальные и максимальные значения, квартили), постройте гистограммы распределения.

Также нужно сравнить поведение клиентов этих двух групп, то есть построить два любых графика, изображающих:
- долю пользователей телефонной связи;
- долю интернет-пользователей.

На основе краткого исследования надо будет предоставить __план__ работы.

В конце тетради необходимо написать __отчет__.

## Описание проекта

Проект выполнен с помощью:
- библиотек *Pandas*, *NumPy*, *Copy*;
- *matplotlib* и *seaborn* - для визуализации;
- средств *scikit-learn*: 
  - алгоритмы ML *RandomForestClassifier* и *LogisticRegression*;
  - *cross_validate* для кросс-валидации; 
  - *train_test_split* для деления на выборки;
  - *StandardScaler* и *OrdinalEncoder* для масштабирования и порядкового кодирования;
  - метрики *accuracy_score* и *roc_auc_score*, а также *roc_curve* для визуализации roc-кривой.
- средств *CatBoost*: *CatBoostClassifier*, а также *cv* и *Pool*;
- средств *LightGBM*: *LGBMClassifier* и *Dataset*.

Перед подробным исследовательским анализом и созданием моделей был разработан план работы.  
После загрузки и предварительного осмотра данных начался этап предобработки, на котором выяснилось, что в одном из столбцов были замаскированные под пробелы пропуски. После изучения они были удалены. Типы данных были приведены к подходящим, был создан столбец, впоследствии послуживший целевым признаком, а также был создан признак, отражающий информацию о жизненном цикле клиента, который впоследствии оказался чрезвычайно важным.
Был проведен анализ данных с визуализацией тех срезов, о которых просили коллеги из маркетинга.  
После объединения датафреймов тип данных ряда признаков был заменен на булевый. Данные были отмасштабированы. Было подготовлено три варианта датасетов, без кодирования категориальных признаков, с прямым и порядковым кодированием. 

Для каждой модели был осуществлен перебор гиперпараметров; результаты (средние по батчам при кросс-валидации) были зафиксированы для каждого сочетания гиперпараметров. Моделям алгоритма *CatBoost* были переданы данные с прямым кодированием и без кодирования категориальных признаков для сравнения. 

В конце результаты лучших моделей каждого алгоритма были сведены в таблицу и сравнены. Лучшей из всех моделей оказалась модель градиентного бустинга *CatBoost*. Она была обучена на полном объеме обучающей/валидационной выборки и проверена на тестовой. Результат превзошел минимальный порог. 

В конце был представлен обширный отчет о проделанной работе. Был рассмотрен вклад каждого признака и визуализирована roc-кривая.
  
  
