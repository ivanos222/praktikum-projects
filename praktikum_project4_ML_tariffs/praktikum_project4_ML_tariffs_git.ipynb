{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мобильный оператор: рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оператор мобильной связи хочет построить систему, способную проанализировать поведение клиентов и предложить пользователям новый, более подходящий каждому отдельному клиенту тариф: «Смарт» или «Ультра».  \n",
    "\n",
    "В нашем распоряжении данные о поведении клиентов с разметкой того, на какой из этих двух тарифов перешел клиент. __Нужно построить модель для задачи классификации, которая выберет подходящий тариф__. Данные уже предобработаны.  \n",
    "\n",
    "По требованию заказчика ключевая метрика - accuracy. Минимальный порог 0.75, но заказчик будет тем больше доволен, чем выше значение.\n",
    "\n",
    "__Дополнительным заданием__ заказчика является проверка модели на адекватность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Предварительный осмотр данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По условию задачи мы должны порекомендовать тариф \"ультра\" или \"смарт\", то есть создать модель, которая на основе данных о звонках, сообщениях и использовании Интернета определяла бы один из двух подходящих вариантов. Таким образом, мы решаем задачу классификации, поэтому использовать мы будем алгоритмы-классификаторы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем все библиотеки и функции, которые могут понадобиться нам для работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем файл и изучим его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('...')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку наша задача - на основе данных о звонках, сообщениях и использовании Интернета порекомендовать тариф, столбец is_ultra будет целевым, а остальные - признаками, на основе которых будет прогнозироваться значение в is_ultra.  \n",
    "Несмотря на то, что тип данных в is_ultra числовой, по сути это булева переменная, принимающая значение 1, если тариф - \"ультра\", и 0, если тариф - \"смарт\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, как распределены значения о тарифах в общем наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30647168637212197"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.query('is_ultra == 1')) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение по тарифам не одинаковое, тарифом \"ультра\" пользуются 30% пользователей из набора. Будем иметь это в виду при разбиении на обучающую, валидационную и тестовую выборки: стратифицируем разбиение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присвоим переменной целое число и будем использовать переменную в качестве зерна для параметра random_state в моделях. Это позволит минимизировать шанс ошибок в случаях, когда нужно будет создать две модели на основании одинаковых алгоритмов с одинаковыми гиперпараметрами, например, когда мы определимся с алгоритмом. Кроме того, это упростит и ускорит работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = 12345 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем набор данных на обучающий, валидационный и тестовый наборы данных в пропорции 60/20/20 соответственно и проверим пропорцию значений в целевом признаке is_ultra в каждом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1928 entries, 2294 to 2134\n",
      "Data columns (total 5 columns):\n",
      "calls       1928 non-null float64\n",
      "minutes     1928 non-null float64\n",
      "messages    1928 non-null float64\n",
      "mb_used     1928 non-null float64\n",
      "is_ultra    1928 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 90.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_train, df_valid_test = train_test_split(df, test_size = 0.4, shuffle = True, stratify = df['is_ultra'], random_state = random)\n",
    "df_valid, df_test = train_test_split(df_valid_test, test_size = 0.5, shuffle = True, stratify = df_valid_test['is_ultra'], random_state = random)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3065352697095436"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.query('is_ultra == 1')) / len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 78 to 2434\n",
      "Data columns (total 5 columns):\n",
      "calls       643 non-null float64\n",
      "minutes     643 non-null float64\n",
      "messages    643 non-null float64\n",
      "mb_used     643 non-null float64\n",
      "is_ultra    643 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30637636080870917"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_valid.query('is_ultra == 1')) / len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 3113 to 691\n",
      "Data columns (total 5 columns):\n",
      "calls       643 non-null float64\n",
      "minutes     643 non-null float64\n",
      "messages    643 non-null float64\n",
      "mb_used     643 non-null float64\n",
      "is_ultra    643 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30637636080870917"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test.query('is_ultra == 1')) / len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных разбит на обучающую, валидационную и тестовую части, пропорция значений 1 и 0 целевого признака в каждой из них соответствует пропорции значений в общем наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop('is_ultra', axis = 1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop('is_ultra', axis = 1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_test.drop('is_ultra', axis = 1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Подбор модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модели, построенные с помощью дерева решений, случайного леса и логистической регрессии с разными гиперпараметрами.  \n",
    "Переберем разные сочетания гиперпараметров и посчитаем для каждого сочетания метрики качества.  \n",
    "Метрик качества у нас будет две: метод score (accuracy_score для дерева решений, значения те же самые, именно ее по заданию нужно довести до порогового значения, и f1_score, при этом со средневзвешенной средней оценкой. Она позволяет чуть более точно определить правильность предсказания для каждого класса отдельно, но при этом благодаря весам класса по количеству значений в выборке не исказится из-за не одинакового распределения значений целевого признака, которые в наших наборах данных распределены в пропорции 30/70.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим дерево рещений с разными сочетаниями значений гиперпараметров. Напишем цикл, перебирающий разные сочетания и рассчитывающий для каждого метрики качества.  \n",
    "Чтобы перебор не занимал излишне много времени, переберем не каждое, а каждое второе значение гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772939</td>\n",
       "      <td>0.757300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772939</td>\n",
       "      <td>0.757300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772939</td>\n",
       "      <td>0.757300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772939</td>\n",
       "      <td>0.757300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.772939</td>\n",
       "      <td>0.757300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.737170</td>\n",
       "      <td>0.731362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.752722</td>\n",
       "      <td>0.748605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.752722</td>\n",
       "      <td>0.748605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.752722</td>\n",
       "      <td>0.748605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.752722</td>\n",
       "      <td>0.748605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  min_samples_split  min_samples_leaf  accuracy_score  f1_score\n",
       "0            2                  2                 1        0.772939  0.757300\n",
       "1            2                  4                 1        0.772939  0.757300\n",
       "2            2                  6                 1        0.772939  0.757300\n",
       "3            2                  8                 1        0.772939  0.757300\n",
       "4            2                  2                 3        0.772939  0.757300\n",
       "..         ...                ...               ...             ...       ...\n",
       "195         20                  8                 7        0.737170  0.731362\n",
       "196         20                  2                 9        0.752722  0.748605\n",
       "197         20                  4                 9        0.752722  0.748605\n",
       "198         20                  6                 9        0.752722  0.748605\n",
       "199         20                  8                 9        0.752722  0.748605\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_depth_col = []\n",
    "tree_min_leaf_col = []\n",
    "tree_min_split_col = []\n",
    "tree_acc_col = []\n",
    "tree_f1_col = []\n",
    "\n",
    "for depth in range(2, 21, 2):\n",
    "    for min_leaf in range(1, 10, 2):\n",
    "        for min_split in range(2,10,2):\n",
    "            model_tree = DecisionTreeClassifier(max_depth = depth, min_samples_split = min_split, min_samples_leaf = min_leaf, random_state = random)\n",
    "            model_tree.fit(features_train, target_train)\n",
    "            predictions_tree = model_tree.predict(features_valid)\n",
    "            acc_score_tree = accuracy_score(target_valid, predictions_tree)\n",
    "            f1_score_tree = f1_score(target_valid, predictions_tree, average = 'weighted')\n",
    "            tree_depth_col.append(depth)\n",
    "            tree_min_split_col.append(min_split)\n",
    "            tree_min_leaf_col.append(min_leaf)\n",
    "            tree_acc_col.append(acc_score_tree)\n",
    "            tree_f1_col.append(f1_score_tree)\n",
    "        \n",
    "tree_hyperparameters_dict = {'max_depth': tree_depth_col, 'min_samples_split': tree_min_split_col, 'min_samples_leaf': tree_min_leaf_col, 'accuracy_score': tree_acc_col, 'f1_score':tree_f1_col}\n",
    "tree_hyperparameters = pd.DataFrame(data = tree_hyperparameters_dict)\n",
    "tree_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем модели с лучшими значениями метрик и взглянем на указанные в них гиперпараметры.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.804044</td>\n",
       "      <td>0.791601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  min_samples_leaf  accuracy_score  f1_score\n",
       "67          8                  8                 3        0.804044  0.791601"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_hyperparameters.query('accuracy_score == accuracy_score.max()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>score</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.804044</td>\n",
       "      <td>0.804044</td>\n",
       "      <td>0.791601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  min_samples_split  min_samples_leaf     score  accuracy_score  \\\n",
       "454          8                  8                 3  0.804044        0.804044   \n",
       "\n",
       "     f1_score  \n",
       "454  0.791601  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_hyperparameters.query('f1_score == f1_score.max()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обе метрики указывают на одинаквое сочетание значений гиперпараметров. В принципе, полученного на валидационной выборке значения accuracy достаточно, чтобы попробовать провериться на тестовой. Но дерево обучения склонно к переобучению, и показатели accuracy модели на этом алгоритме на тестовой выборке могут оказаться ниже, чем у моделей, обученных с помощью случайного леса или логистической регрессии.  \n",
    "Поэтому рассмотрим другие алгоритмы, если результаты метрик качества будут сопоставимы, лучше будет отдать предпочтение им."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переберем сочетания гиперпараметров для случайного леса. Перебор может занять много времени, поскольку количество рассматриваемых гиперпараметров увеличивается: появляется количество деревьев. Шаг для него сделаем больше, также изменим количество рассматриваемых решений для других параметров, чтобы у нас появился шанс дождаться перебора сочетаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776050</td>\n",
       "      <td>0.743149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785381</td>\n",
       "      <td>0.762724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.793157</td>\n",
       "      <td>0.774360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.793157</td>\n",
       "      <td>0.774360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776050</td>\n",
       "      <td>0.743149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.810264</td>\n",
       "      <td>0.800151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.791602</td>\n",
       "      <td>0.777248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805599</td>\n",
       "      <td>0.793511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800933</td>\n",
       "      <td>0.790806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.810264</td>\n",
       "      <td>0.800151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  n_estimators  min_samples_split  min_samples_leaf     score  \\\n",
       "0            2            10                  2                 1  0.776050   \n",
       "1            2            20                  2                 1  0.785381   \n",
       "2            2            30                  2                 1  0.793157   \n",
       "3            2            40                  2                 1  0.793157   \n",
       "4            2            10                  4                 1  0.776050   \n",
       "..         ...           ...                ...               ...       ...   \n",
       "247         14            40                  4                 5  0.810264   \n",
       "248         14            10                  6                 5  0.791602   \n",
       "249         14            20                  6                 5  0.805599   \n",
       "250         14            30                  6                 5  0.800933   \n",
       "251         14            40                  6                 5  0.810264   \n",
       "\n",
       "     f1_score  \n",
       "0    0.743149  \n",
       "1    0.762724  \n",
       "2    0.774360  \n",
       "3    0.774360  \n",
       "4    0.743149  \n",
       "..        ...  \n",
       "247  0.800151  \n",
       "248  0.777248  \n",
       "249  0.793511  \n",
       "250  0.790806  \n",
       "251  0.800151  \n",
       "\n",
       "[252 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_depth_col = []\n",
    "forest_estim_col = []\n",
    "forest_min_leaf_col = []\n",
    "forest_min_split_col = []\n",
    "forest_score_col = []\n",
    "forest_f1_col = []\n",
    "\n",
    "for depth in range(2,16,2):\n",
    "    for min_leaf in range(1, 6, 2):\n",
    "        for min_split in range(2,8,2):\n",
    "            for estim in range(10, 50, 10):\n",
    "                model_forest = RandomForestClassifier(n_estimators = estim, max_depth = depth, min_samples_split = min_split, min_samples_leaf = min_leaf, random_state = random)\n",
    "                model_forest.fit(features_train, target_train)\n",
    "                predictions_forest = model_forest.predict(features_valid)\n",
    "                score_forest = model_forest.score(features_valid, target_valid)\n",
    "                f1_forest = f1_score(target_valid, predictions_forest, average = 'weighted')\n",
    "                forest_depth_col.append(depth)\n",
    "                forest_min_leaf_col.append(min_leaf)\n",
    "                forest_min_split_col.append(min_split)\n",
    "                forest_estim_col.append(estim)\n",
    "                forest_score_col.append(score_forest)\n",
    "                forest_f1_col.append(f1_forest)\n",
    "        \n",
    "        \n",
    "forest_hyperparameters_dict = {'max_depth': forest_depth_col, 'n_estimators': forest_estim_col, 'min_samples_split': forest_min_split_col, 'min_samples_leaf': forest_min_leaf_col, 'score': forest_score_col, 'f1_score':forest_f1_col}\n",
    "forest_hyperparameters = pd.DataFrame(data = forest_hyperparameters_dict)\n",
    "forest_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим модели с лучшей метрикой score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>0.808613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>0.807170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  n_estimators  min_samples_split  min_samples_leaf     score  \\\n",
       "110          8            30                  2                 1  0.819596   \n",
       "115          8            40                  4                 1  0.819596   \n",
       "\n",
       "     f1_score  \n",
       "110  0.808613  \n",
       "115  0.807170  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_hyperparameters.query('score == score.max()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечательно, что в результате перебора у нас появилось две модели с разными гиперпараметрами, но одинаковыми показателями качества. Это можно было бы объяснить тем, что некоторые гиперпараметры задают не точное количество глубины или объектов в листьях, а максимальное, в то время как соответствующие параметры у моделей могут совпадать.  \n",
    "Однако в этом случае это не так, поскольку различаются значения в гиперпараметре n_estimators, задающее точное количество деревьев в лесу.  \n",
    "В любом случае, нам повезло, что мы рассматривали не единственную метрику качесва. Различающиеся значения f1_score свидетельствуют о том, что, может, общее количество правильных ответов в моделях и одинаковое, в одном из случаев это количество распределено по классам более пропорционально.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>0.808613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  n_estimators  min_samples_split  min_samples_leaf     score  \\\n",
       "110          8            30                  2                 1  0.819596   \n",
       "\n",
       "     f1_score  \n",
       "110  0.808613  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_hyperparameters.query('f1_score == f1_score.max()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес более устойчив к переобучению, чем дерево решений, поэтому предпочтение отдаем ему. Тем более, показатели качества в его случае выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия работает быстрее, чем случайный лес, поэтому при одинаковой точности предпочтение стоит отдать ей, хотя если точность будет ниже, то выберем мы случайный лес, так как заказчик поставил пороговое значение по точности, а не по быстродействию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.71850699844479\n",
      "f1_score: 0.644571277664623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state = random)\n",
    "logreg.fit(features_train, target_train)\n",
    "predictions_logreg = logreg.predict(features_valid)\n",
    "score_logreg = logreg.score(features_valid, target_valid)\n",
    "f1_score_logreg = f1_score(target_valid, predictions_logreg, average = 'weighted')\n",
    "print('score:', score_logreg)\n",
    "print('f1_score:', f1_score_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показатели качества на валидационной выборке гораздо ниже, чем у предыдущих алгоритмов, поэтому оставляем свой предыдущий выбор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_depth = int(forest_hyperparameters.loc[forest_hyperparameters['f1_score'] == forest_hyperparameters['f1_score'].max(), \n",
    "                                            'max_depth'])\n",
    "best_estim = int(forest_hyperparameters.loc[forest_hyperparameters['f1_score'] == forest_hyperparameters['f1_score'].max(), \n",
    "                                            'n_estimators'])\n",
    "best_split =int(forest_hyperparameters.loc[forest_hyperparameters['f1_score'] == forest_hyperparameters['f1_score'].max(), \n",
    "                                           'min_samples_split'])\n",
    "best_leaf =int(forest_hyperparameters.loc[forest_hyperparameters['f1_score'] == forest_hyperparameters['f1_score'].max(), \n",
    "                                          'min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055987558320373"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_model = RandomForestClassifier(max_depth = best_depth, \n",
    "                                    n_estimators = best_estim, \n",
    "                                    min_samples_split = best_split, \n",
    "                                    min_samples_leaf = best_leaf, \n",
    "                                    random_state = random)\n",
    "best_model.fit(features_train, target_train)\n",
    "best_predictions = best_model.predict(features_test)\n",
    "best_score = best_model.score(features_test, target_test)\n",
    "best_f1_score = f1_score(target_test, best_predictions, average = 'weighted')\n",
    "\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7968549064971004"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показатели качества выбранной модели на тестовой выборке переступили пороговое значение, значит, задача-минимум выполнена. Однако заказчик просит довести количество правильных ответов до максимального. Мы можем это сделать, если обучим модель не на первоначально выбранном обучающем наборе, а на объединении первоначальных обучающих и валидационных выборок. Посмотрим, улучшит ли это результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289269051321928"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final = df_train.append(df_valid, ignore_index = True)\n",
    "features_train_final = df_train_final.drop('is_ultra', axis = 1)\n",
    "target_train_final = df_train_final['is_ultra']\n",
    "\n",
    "best_model_final = best_model.fit(features_train_final, target_train_final)\n",
    "\n",
    "best_predictions_final = best_model_final.predict(features_test)\n",
    "best_score_final = best_model_final.score(features_test, target_test)\n",
    "best_f1_score_final = f1_score(target_test, best_predictions_final, average = 'weighted')\n",
    "\n",
    "best_score_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8176081973240633"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1_score_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат улучшен, модель, рекомендующая тарифы подобрана."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (бонус) Проверка модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель, которая будет генерировать случайные предсказания с помощью Dummy Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.583203732503888"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "random_model = DummyClassifier()\n",
    "random_model.fit(features_train_final, target_train_final)\n",
    "random_model.score(features_test, target_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5769828926905132"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5583203732503889"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536547433903577"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.578538102643857"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5412130637636081"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396578538102644"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5956454121306376"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что значения accuracy больше 0.5, поскольку стратегия случайного прогнозирования по умолчанию stratified, то есть дает случайные прогнозы не 50/50, а в соответствии с пропорцией классов в выборке, поэтому accuracy рассчитывается по формуле 0.3 * 0.3 + 0.7 * 0.7 = 0.58, а не 0.5 * 0.3 + 0.5 * 0.7 = 0.5.  \n",
    "Впрочем, это даже еще очевиднее демонстрирует, что тест на вменяемость пройден: метрики качества нашей модели выше каждого из этих значений.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49922239502332816"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totally_random_model = DummyClassifier(strategy = 'uniform')\n",
    "totally_random_model.fit(features_train_final, target_train_final)\n",
    "totally_random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5023328149300156"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totally_random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5147744945567652"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totally_random_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более стандартный тест на вменяемость с абсолютно случайными прогнозами 50/50 тоже пройден."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
